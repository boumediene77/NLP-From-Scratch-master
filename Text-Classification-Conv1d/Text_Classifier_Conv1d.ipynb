{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AMAL_tme8",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXYHt8ohZjNL",
        "outputId": "7d845ad7-bc76-4c7a-97a6-23a58e7ebca1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |▌                               | 20 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |▉                               | 30 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█                               | 40 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 51 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 61 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |██                              | 71 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 81 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 92 kB 3.9 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 102 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███                             | 112 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 122 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 133 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 143 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████                            | 153 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 163 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 174 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 184 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 194 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 204 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 215 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████                          | 225 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 235 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 245 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 256 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████                         | 266 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 276 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 286 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 296 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████                        | 307 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 317 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 327 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 337 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 348 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 358 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 368 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 378 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 389 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 399 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 409 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 419 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 430 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 440 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 450 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 460 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 471 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 481 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 491 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 501 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 512 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 522 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 532 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 542 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 552 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 563 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 573 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 583 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 593 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 604 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 614 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 624 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 634 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 645 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 655 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 665 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 675 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 686 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 696 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 706 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 716 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 727 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 737 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 747 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 757 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 768 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 778 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 788 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 798 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 808 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 819 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 829 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 839 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 849 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 860 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 870 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 880 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 890 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 901 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 911 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 921 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 931 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 942 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 952 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 962 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 972 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 983 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 993 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.0 MB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.0 MB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.0 MB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.0 MB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.0 MB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.1 MB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.1 MB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.1 MB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.1 MB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.1 MB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.1 MB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.1 MB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.1 MB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.1 MB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.1 MB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.2 MB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.2 MB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.2 MB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.2 MB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.2 MB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.2 MB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.2 MB 4.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r http://webia.lip6.fr/~baskiotisn/requirements-amal.txt"
      ],
      "metadata": {
        "id": "dTYRn9kRaEcB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1D2_wfgYZdt"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "\n",
        "from torch.nn.modules.pooling import MaxPool1d\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "import heapq\n",
        "from pathlib import Path\n",
        "import gzip\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import sentencepiece as spm\n",
        "import math\n",
        "from tp8_preprocess import TextDataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime"
      ],
      "metadata": {
        "id": "F0z60-diZfFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Utiliser tp8_preprocess pour générer le vocabulaire BPE et\n",
        "# le jeu de donnée dans un format compact\n",
        "\n",
        "# --- Configuration\n",
        "\n",
        "# Taille du vocabulaire\n",
        "vocab_size = 1000\n",
        "#MAINDIR = Path(__file__).parent\n",
        "MAINDIR = Path('.').parent\n",
        "# Chargement du tokenizer\n",
        "\n",
        "tokenizer = spm.SentencePieceProcessor()\n",
        "tokenizer.Load(f\"wp{vocab_size}.model\")\n",
        "ntokens = len(tokenizer)\n",
        "\n",
        "def loaddata(mode):\n",
        "    with gzip.open(f\"{mode}-{vocab_size}.pth\", \"rb\") as fp:\n",
        "        return torch.load(fp)"
      ],
      "metadata": {
        "id": "1zwKUCC8Zg35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = loaddata(\"test\")\n",
        "train = loaddata(\"train\")\n",
        "TRAIN_BATCHSIZE=64\n",
        "TEST_BATCHSIZE=64"
      ],
      "metadata": {
        "id": "oIGAEj0WaR-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_size = 10000\n",
        "train_size = len(train) - val_size\n",
        "train, val = torch.utils.data.random_split(train, [train_size, val_size])\n",
        "\n",
        "logging.info(\"Datasets: train=%d, val=%d, test=%d\", train_size, val_size, len(test))\n",
        "logging.info(\"Vocabulary size: %d\", vocab_size)\n",
        "train_iter = torch.utils.data.DataLoader(train, batch_size=TRAIN_BATCHSIZE, collate_fn=TextDataset.collate)\n",
        "val_iter = torch.utils.data.DataLoader(val, batch_size=TEST_BATCHSIZE, collate_fn=TextDataset.collate)\n",
        "test_iter = torch.utils.data.DataLoader(test, batch_size=TEST_BATCHSIZE, collate_fn=TextDataset.collate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsrORJb-abkj",
        "outputId": "92781b0f-0617-4240-ac61-37a8c5bde1e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Datasets: train=1590000, val=10000, test=359\n",
            "INFO:root:Vocabulary size: 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_len = next(iter(train_iter))[0].shape[1]\n",
        "seq_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qt98PtKjbZx-",
        "outputId": "64f15bdf-4fd0-46ec-a411-494a2974dab6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Classifier(torch.nn.Module):\n",
        "    def __init__(self, seq_len, num_words, emb_size, num_class):\n",
        "        super(Classifier, self).__init__()\n",
        "        \n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        \n",
        "        self.kernel_1 = 3\n",
        "        self.kernel_2 = 3\n",
        "        self.kernel_3 = 3\n",
        "        \n",
        "        self.out_1 = 64\n",
        "        self.out_2 = 32\n",
        "        self.out_3 = 1\n",
        "        \n",
        "        self.kernel_pool = 2\n",
        "        self.stride_pool = 2\n",
        "        \n",
        "        self.dense_size_1 = 128\n",
        "        self.dense_size_2 = 16\n",
        "        \n",
        "        self.embedding = nn.Embedding(num_words, emb_size, padding_idx=0)\n",
        "        \n",
        "        self.conv1 = nn.Conv1d(emb_size, self.out_1, self.kernel_1)\n",
        "        self.pool1 = nn.MaxPool1d(self.kernel_pool, self.stride_pool)\n",
        "\n",
        "        self.conv2 = nn.Conv1d(self.out_1, self.out_2, self.kernel_2)\n",
        "        self.pool2 = nn.MaxPool1d(self.kernel_pool, self.stride_pool)\n",
        "        \n",
        "        self.conv3 = nn.Conv1d(self.out_2, self.out_3, self.kernel_2)\n",
        "        #self.pool2 = nn.MaxPool1d(self.kernel_pool, self.stride_pool)\n",
        "        self.pool3 = nn.AdaptiveAvgPool1d(self.dense_size_1)\n",
        "        \n",
        "        #self.fc = nn.Linear((int((math.floor(self.out_2 - (self.kernel_pool - 1) - 1) / self.stride_pool)) + 1)*num_class, num_class)\n",
        "        self.fc1 = nn.Linear(self.dense_size_1, self.dense_size_2)\n",
        "        self.fc2 = nn.Linear(self.dense_size_2, num_class)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x = self.conv1(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.pool1(x)\n",
        "        \n",
        "        x = self.conv2(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.pool3(x)\n",
        "        \n",
        "        x = x.squeeze(dim=1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.dropout(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "yMBtOHdXbeIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "yOLk9jEzblOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(dataloader, model, optimizer):\n",
        "    train_loss, train_acc = 0, 0\n",
        "    L = nn.CrossEntropyLoss()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "        yhat = model(X.long())\n",
        "        loss = L(yhat, y)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "        _, pred = torch.max(yhat, 1)\n",
        "        train_acc += (torch.sum( pred == y) / dataloader.batch_size).item()\n",
        "    return train_loss / len(dataloader), train_acc / len(dataloader)"
      ],
      "metadata": {
        "id": "azqP-ZIbbsrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_loop(dataloader, model):\n",
        "    test_loss, test_acc = 0, 0\n",
        "    L = nn.CrossEntropyLoss()\n",
        "    with torch.no_grad():\n",
        "        for batch, (X, y) in enumerate(dataloader):\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "            yhat = model(X.long())\n",
        "            loss = L(yhat, y)\n",
        "            test_loss += loss.item()\n",
        "            _, pred = torch.max(yhat, 1)\n",
        "            test_acc += (torch.sum( pred == y) / dataloader.batch_size).item()\n",
        "    return test_loss / len(dataloader), test_acc / len(dataloader)"
      ],
      "metadata": {
        "id": "d3qqZsoOb66R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class State:\n",
        "    def __init__(self, model, optim):\n",
        "        self.model = model\n",
        "        self.optimizer = optim\n",
        "        self.epoch, self.iteration = 0, 0"
      ],
      "metadata": {
        "id": "6fxGlzbkb_Zr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(data_train, data_val, data_test, save_path, Model, tensorboard_name, iterations=500):\n",
        "    if save_path.is_file():\n",
        "        with save_path.open('rb') as fp:\n",
        "            state = torch.load(fp)\n",
        "    else :\n",
        "        model = Model(seq_len ,vocab_size, 100, 3).to(device)\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=0.0003)\n",
        "        state = State(model, optimizer)\n",
        "    for epoch in range(state.epoch, iterations):\n",
        "        loss_train, acc_train = train_loop(data_train, state.model, state.optimizer)\n",
        "        with save_path.open(\"wb\") as fp:\n",
        "            state.epoch = epoch + 1\n",
        "            torch.save(state, fp)\n",
        "        loss_val, acc_val = test_loop(data_val, state.model)\n",
        "        \n",
        "        train_writer.add_scalar(tensorboard_name+'/loss',loss_train , epoch)\n",
        "        val_writer.add_scalar(tensorboard_name+'/loss',loss_val , epoch)\n",
        "\n",
        "        train_writer.add_scalar(tensorboard_name+'/accuracy', acc_train, epoch)\n",
        "        val_writer.add_scalar(tensorboard_name+'/accuracy', acc_val, epoch)\n",
        "        \n",
        "        print('Epoch:', epoch, '\\n Loss val: ', loss_val, 'Loss train: ',loss_train, '\\nAcc val: ',acc_val, ' Acc train: ', acc_train, '\\n\\n')\n",
        "    print(\"Done!\")\n",
        "    return state.model"
      ],
      "metadata": {
        "id": "CxAV5JY1cafw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "savepath1 = Path('./model1.pt')\n",
        "train_writer = SummaryWriter(\"runs/train\"+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "val_writer = SummaryWriter(\"runs/val\"+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "model1 = train(train_iter, val_iter, test_iter, savepath1, Classifier, \"Classifier\" ,iterations=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 830
        },
        "id": "na-SWkPkcd-D",
        "outputId": "31a7bbd2-fdf8-440e-8872-467f10430aba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 \n",
            " Loss val:  0.5488508377864862 Loss train:  0.5947614106072394 \n",
            "Acc val:  0.7466162420382165  Acc train:  0.7192990510787313 \n",
            "\n",
            "\n",
            "Epoch: 1 \n",
            " Loss val:  0.5404257083394725 Loss train:  0.5363286883478636 \n",
            "Acc val:  0.7584593949044586  Acc train:  0.7673029705361456 \n",
            "\n",
            "\n",
            "Epoch: 2 \n",
            " Loss val:  0.5312828710124751 Loss train:  0.5206520000907212 \n",
            "Acc val:  0.7682125796178344  Acc train:  0.7771777139349542 \n",
            "\n",
            "\n",
            "Epoch: 3 \n",
            " Loss val:  0.52356941286166 Loss train:  0.510523721123496 \n",
            "Acc val:  0.7659235668789809  Acc train:  0.7832826839478345 \n",
            "\n",
            "\n",
            "Epoch: 4 \n",
            " Loss val:  0.5351616419424676 Loss train:  0.5029902684851231 \n",
            "Acc val:  0.767515923566879  Acc train:  0.7874511954596684 \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-100-a934f0697066>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrain_writer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"runs/train\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%Y%m%d-%H%M%S\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mval_writer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"runs/val\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%Y%m%d-%H%M%S\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msavepath1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Classifier\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-99-75c3b6b6e083>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(data_train, data_val, data_test, save_path, Model, tensorboard_name, iterations)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mloss_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-96-3614429e3681>\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(dataloader, model, optimizer)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = 0, 0\n",
        "L = nn.CrossEntropyLoss()\n",
        "with torch.no_grad():\n",
        "    for batch, (X, y) in enumerate(test_iter):\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "        yhat = model1(X.long())\n",
        "        loss = L(yhat, y)\n",
        "        test_loss += loss.item()\n",
        "        _, pred = torch.max(yhat, 1)\n",
        "        test_acc += (torch.sum( pred == y) / test_iter.batch_size).item()\n",
        "print(test_loss / len(test_iter), test_acc / len(test_iter))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yal1_yQWckwj",
        "outputId": "cf2d3068-9b77-44af-de36-0e2ed2fffada"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6391860942045847 0.6510416666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rSFmb6ESKTOP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}